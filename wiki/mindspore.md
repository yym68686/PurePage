# PyTorch to MindSpore ç¿»è¯‘å…¨æµç¨‹æ¢³ç†

ğŸ”— é¡¹ç›®é“¾æ¥ï¼šhttps://github.com/yym68686/ACL-DGReID-mindspore

## å‰è¨€

è¯¥é¡¹ç›®ä»»åŠ¡æ˜¯å°† [Adaptive Cross-Domain learning for Generalizable Person Re-Identification](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136740209.pdf) è®ºæ–‡çš„[åŸå§‹ PyTorch ä»£ç ](https://github.com/peterzpy/ACL-DGReID) ç¿»è¯‘åˆ° MindSpore ä»£ç ç‰ˆæœ¬ã€‚å·²å®Œæˆæ•´ä¸ªç½‘ç»œçš„å¯¹é½ï¼Œä½†è¿˜ä¸èƒ½è®­ç»ƒã€‚æœ¬é¡¹ç›®åŸºäº mindspore 2.2 ç‰ˆæœ¬ã€‚

## ç¿»è¯‘æ€è·¯

- å…ˆæŠŠåŸæ¥çš„æ¨¡å‹å­¦ä¼šè·‘èµ·æ¥ã€‚
- ç½‘ç»œç¿»è¯‘ï¼šä¸»è¦å°±æ˜¯ API æ˜ å°„ï¼Œé¦–å…ˆæŠŠä¸»å¹²ç½‘ç»œç¿»è¯‘å¥½ã€‚pytorch åˆ° mindspore ä»£ç çš„æ˜ å°„å¯ä»¥å‚è€ƒä¸‹é¢çš„å°èŠ‚ API æ˜ å°„ã€‚
- ç½‘ç»œè¾“å‡ºå¼ é‡å¯¹é½ï¼šåœ¨ç»™ç½‘ç»œåšåˆæ­¥ç¿»è¯‘åï¼Œéœ€è¦ä¿è¯ç¿»è¯‘çš„æ­£ç¡®æ€§ï¼Œéœ€è¦è¿›è¡Œä¸»å¹²ç½‘ç»œå¯¹é½ã€‚æµ‹è¯• pytorch ä¸ mindspore ç›¸åº”ä¸»å¹²ç½‘ç»œåœ¨ç›¸åŒçš„è¾“å…¥å¼ é‡ä¸‹ï¼Œæ˜¯å¦å¯æ˜¯è¾“å‡ºä¸€æ ·æ•°å€¼çš„å¼ é‡ã€‚éœ€è¦è¿›è¡Œå•å…ƒæµ‹è¯•ï¼Œå°±æ˜¯æŠŠä¸»å¹²ç½‘ç»œæ‹†åˆ†ä¸ºä¸€ä¸ªä¸ªå°çš„ç½‘ç»œæ¨¡å—ã€‚å¯ä»¥ä½¿ç”¨ python çš„ unittest æ¨¡å—åšå•å…ƒæµ‹è¯•ã€‚å•å…ƒæµ‹è¯•å¯ä»¥å‚è€ƒ test/unitest/test.py ä»£ç ã€‚æœ¬é¡¹ç›®å·²å®Œæˆç½‘ç»œè¾“å‡ºå¼ é‡å¯¹é½ã€‚
  - å‚æ•°æ˜ å°„ï¼špytorch ä¸ mindspore å‚æ•°åæœ‰äº›ä¸ä¸€æ ·ï¼Œæ¯”å¦‚ mindspore é‡Œé¢çš„ moving_meanï¼Œmoving_varianceï¼Œgammaï¼Œbetaã€‚æ„å»ºä¸€ä¸ªæœ‰åºå­—å…¸ï¼Œå°†ä¸¤ä¸ªæ¡†æ¶çš„å‚æ•°ä¸€ä¸€å¯¹åº”èµ·æ¥ï¼Œå®˜ç½‘[è„šæœ¬](https://www.mindspore.cn/docs/zh-CN/r2.0/migration_guide/sample_code.html?highlight=num_batches_tracked#%E5%8F%82%E6%95%B0%E6%98%A0%E5%B0%84%E5%8F%8Acheckpoint%E4%BF%9D%E5%AD%98)ã€‚æˆ‘å†™å¥½çš„å‚æ•°åè½¬æ¢è„šæœ¬å¯ä»¥å‚è€ƒ test/unitest/pth2ckpt.py ä»£ç ã€‚
  - æƒé‡è¿ç§»ï¼šæŠŠ pytorch é¢„è®­ç»ƒæ¨¡å‹é‡Œé¢ç½‘ç»œæƒé‡è¿ç§»åˆ° mindspore ä¸­ï¼Œç”¨æ¥å›ºå®šç½‘ç»œçš„æƒé‡ï¼Œpytorch æƒé‡æ–‡ä»¶ pth ä¸èƒ½å’Œ mindspore ckpt æ–‡ä»¶é€šç”¨ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨ pth to ckpt è½¬æ¢è„šæœ¬ï¼Œå®˜ç½‘[è¯´æ˜ä¸è„šæœ¬](https://www.mindspore.cn/docs/zh-CN/r2.0/faq/usage_migrate_3rd.html)ã€‚è¯¥é¡¹ç›®å·²åœ¨ test/unitest/test.py ä¸­å®ç°ã€‚

- å®Œæˆä¸Šé¢çš„æ­¥éª¤å°±è·‘é€šåŠ¨æ€å›¾äº†ã€‚
- ä¸‹é¢éœ€è¦è·‘é€šé™æ€å›¾ã€‚
- ç¼–å†™è®­ç»ƒä»£ç ã€‚

## ç¯å¢ƒå®‰è£…

å®‰è£… pytorch mindspore åŒç¯å¢ƒï¼Œä¿è¯ cuda ç‰ˆæœ¬ä¸€æ ·

åˆ›å»ºç¯å¢ƒ

```bash
conda create -y -n reid python=3.9
```

CUDA 11.6

```bash
conda install -y mindspore=2.2.14 -c mindspore -c conda-forge
conda install -y pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia
```

CUDA 11.1

```bash
# python<=3.8
conda install python=3.8 mindspore=2.2.11 pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c mindspore -c conda-forge -c nvidia

conda install mindspore=2.2.11 -c mindspore -c conda-forge
conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia

conda install -y pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=10.2
```

CUDA 10.1

```bash
conda install python=3.8
conda install mindspore=2.2.0 -c mindspore -c conda-forge
conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch
pip install protobuf==3.20.3
```

ç¡®è®¤æ˜¯å¦ mindspore GPU å®‰è£…æˆåŠŸ

```bash
python -c "import mindspore;mindspore.set_context(device_target='GPU');mindspore.run_check()"
python -c "import torch; print(torch.cuda.is_available())"
```

å®‰è£…ä¾èµ–

```bash
pip install -q -r requirements.txt
```

æ•°æ®é›†åŒæ­¥

```bash
rsync -av --partial --progress /Users/yanyuming/Downloads/æ–‡ä»¶/split_reid_data.zip 40:/data/yuming
```

æ•°æ®é›†è§£å‹

```bash
unzip split_reid_data.zip -x "__MACOSX/*"
```

è°ƒæ•´æµ‹è¯•æ•°æ®é›†

```bash
sed -i 's|/4T/yuhan/datasets/reid_data/|/data0/yuming/split_reid_data/|g' /data0/yuming/split_reid_data/cuhk03_new/splits_new_labeled.json
```

ä¼ è¾“é¢„è®­ç»ƒæƒé‡

```bash
mkdir -p /home/yuming/.cache/torch/checkpoints/
mv ~/resnet50_ibn_a-d9d0bb7b.ckpt /home/yuming/.cache/torch/checkpoints/
mv ~/resnet50_ibn_a-d9d0bb7b.pth /home/yuming/.cache/torch/checkpoints/

# pth
scp -r 41:/home/yuming/.cache/torch/checkpoints/resnet50_ibn_a-d9d0bb7b.pth /Users/yanyuming/Desktop/
scp -r /Users/yanyuming/Desktop/resnet50_ibn_a-d9d0bb7b.pth 40:/home/yuming/.cache/torch/checkpoints/

# ckpt
scp -r 41:/home/yuming/.cache/torch/checkpoints/resnet50_ibn_a-d9d0bb7b.ckpt /Users/yanyuming/Desktop/
scp -r /Users/yanyuming/Desktop/resnet50_ibn_a-d9d0bb7b.ckpt 40:/home/yuming/.cache/torch/checkpoints/
```

è°ƒè¯• launch.json

```json
{
    // ä½¿ç”¨ IntelliSense äº†è§£ç›¸å…³å±æ€§ã€‚ 
    // æ‚¬åœä»¥æŸ¥çœ‹ç°æœ‰å±æ€§çš„æè¿°ã€‚
    // æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: å½“å‰æ–‡ä»¶",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--config-file", "./configs/bagtricks_DR50_mix.yml",
                "--num-gpus", "4"
            ]
        }
    ]
}
```


## Requirements

+ CUDA>=10.0
+ At least four 1080-Ti GPUs
+ Setup could refer to [INSTALL.md](INSTALL.md)
+ Other necessary packages listed in [requirements.txt](requirements.txt)
+ Training Data
  The model is trained and evaluated on Market-1501, MSMT17, cuhkSYSU, CUHK03. Download for these datasets, please refer to [fast-reid](https://github.com/JDAI-CV/fast-reid).

## è¿è¡Œ

```bash
# env
pip install -r requirements.txt
# train
python copy_launch.py
CUDA_VISIBLE_DEVICES=0,1,2,3 python3 tools/train_net.py --config-file ./configs/bagtricks_DR50_mix.yml --num-gpus 4
CUDA_VISIBLE_DEVICES=0 nohup python3 -u tools/train_net.py --config-file ./configs/bagtricks_DR50_mix.yml --num-gpus 1 > nohup.out 2>&1 &
pgrep -f 'train_net.py' | grep -v grep | xargs kill -9

# test
python3 tools/train_net.py --config-file ./configs/bagtricks_DR50_mix.yml --eval-only MODEL.WEIGHTS /path/to/checkpoint_file MODEL.DEVICE "cuda:0"
```

## API æ˜ å°„

ä¸‹é¢æ˜¯ PyTorch å‡½æ•°åœ¨ MindSpore é‡Œé¢çš„æ˜ å°„ï¼Œä»¥ä¸‹æ˜ å°„éƒ½æ˜¯æˆ‘ä¸ªäººç»éªŒçš„æ€»ç»“ï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶ç”¨èµ·æ¥ã€‚

```python
# PyTorch
nn.Module

# MindSpore
nn.Cell


# PyTorch
nn.ReLU(inplace=True)

# MindSpore
nn.ReLU()


# PyTorch
nn.Sigmoid()

# MindSpore
nn.Sigmoid()


# PyTorch
nn.Parameter()

# MindSpore
mindspore.Parameter()


# PyTorch å›¾æ„é€ 
forward

# MindSpore å›¾æ„é€ 
construct


# PyTorch Sequential
nn.Sequential
# æˆ–è€…
nn.ModuleList

# MindSpore SequentialCell
nn.SequentialCell


# PyTorch 
tensor.size()

# MindSpore
tensor.shape


# PyTorch 
tensor.size(0)

# MindSpore
tensor.shape[0]


# PyTorch å¸¦ padding çš„ MaxPool2d
maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

# MindSpore å¸¦ padding çš„ MaxPool2d
maxpool = nn.SequentialCell([
              nn.Pad(paddings=((0, 0), (0, 0), (1, 1), (1, 1)), mode="CONSTANT"),
              nn.MaxPool2d(kernel_size=3, stride=2)])


# PyTorch å…¨è¿æ¥
fc = nn.Linear(in_features, out_features, bias=True)

# MindSpore å…¨è¿æ¥ï¼Œå‚æ•°åä¸ä¸€è‡´
# https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/note/api_mapping/pytorch_diff/Dense.html
fc = nn.Dense(in_channels, out_channels, has_bias=True)


# PyTorch
torch.nn.functional.linear(inputs, self.weight, self.bias)

# MindSpore
mindspore.ops.dense(input, weight, bias=None)
# æˆ–è€…
# MindSporeï¼Œéœ€è¦å®ä¾‹åŒ–ï¼Œbias åç½®å¼ é‡ï¼Œå½¢çŠ¶ä¸º (out_channels,)
linear = mindspore.nn.Dense(self.in_feat, self.bias.shape[0])
linear.weight = self.weight
linear.bias = self.bias
output = linear(inputs)


# PyTorch AdaptiveAvgPool2d
nn.AdaptiveAvgPool2d(1)
# æˆ–
nn.AdaptiveAvgPool2d((1, 1))

# MindSpore ReduceMean å’Œ AdaptiveAvgPool2d output shapeæ˜¯1æ—¶åŠŸèƒ½ä¸€è‡´ï¼Œä¸”é€Ÿåº¦ä¼šå¿«
# é»˜è®¤æƒ…å†µä¸‹ï¼Œä½¿ç”¨æŒ‡å®šç»´åº¦çš„å¹³å‡å€¼ä»£æ›¿è¯¥ç»´åº¦çš„å…¶ä»–å…ƒç´ ï¼Œä»¥ç§»é™¤è¯¥ç»´åº¦ã€‚ä¹Ÿå¯ä»…ç¼©å°è¯¥ç»´åº¦å¤§å°è‡³1ã€‚
# é€šè¿‡æŒ‡å®š keep_dims å‚æ•°ï¼Œæ¥æ§åˆ¶è¾“å‡ºå’Œè¾“å…¥çš„ç»´åº¦æ˜¯å¦ç›¸åŒã€‚
# https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/ops/mindspore.ops.ReduceMean.html
# å®˜ç½‘ç»™å‡ºçš„æ›¿æ¢ï¼šhttps://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/migration_guide/sample_code.html
op = ops.ReduceMean(keep_dims=True)
output = op(x, tuple(range(len(x.shape)))[-2:])


# PyTorch
split = torch.split(inputs, self.half, 1)

# MindSpore
split = mindspore.ops.split(inputs, self.half, 1)


# PyTorch
out = torch.cat((out1, out2), dim=1)

# MindSpore
# https://www.mindspore.cn/docs/zh-CN/r2.0/note/api_mapping/pytorch_diff/cat.html
out = mindspore.ops.cat((out1, out2), axis=1)


# PyTorch
# stride: çª—å£çš„æ­¥é•¿ã€‚å¯ä»¥æ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—æˆ–è€…ä¸€ä¸ªå…ƒç»„ (sW,)ã€‚é»˜è®¤å€¼æ˜¯ kernel_sizeã€‚
torch.nn.functional.avg_pool1d(input_x, kernel_size=2, stride=2)

# MindSporeï¼Œavg_pool1dè¾“å…¥å¿…é¡»æ˜¯ä¸‰ç»´çš„ï¼ŒPyTorch æ²¡æœ‰é™åˆ¶
# stride: çª—å£çš„æ­¥é•¿ã€‚å¯ä»¥æ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—æˆ–è€…ä¸€ä¸ªå…ƒç»„ (sW,)ã€‚é»˜è®¤å€¼æ˜¯ 1ã€‚
output = mindspore.ops.avg_pool1d(input_x, kernel_size=2, stride=2)


# PyTorch
ret = Tensor(data).permute((3, 2, 1, 0))

# MindSpore
ret = ops.Transpose()(ms.Tensor(data), (3, 2, 1, 0))


# PyTorch
torch.Tensor.transpose(0, 1)

# MindSpore
mindspore.Tensor.swapaxes(0, 1)


# PyTorch
x.repeat(2, 2)

# MindSporeï¼Œä¸èƒ½ç”¨ repeatï¼Œå› ä¸º repeat åé‡Œé¢çš„å¤åˆ¶å…ƒç´ æ˜¯è¿ç»­çš„
x.tile((2, 2))


# PyTorchï¼Œæ•°æ®å¯¹è±¡ï¼Œåœ¨è¾ƒæ—§çš„ PyTorch ç‰ˆæœ¬ä¸­ä½¿ç”¨
Variable

# MindSporeï¼Œæ ¹æ®ä¸Šé¢çš„çŸ¥è¯†ï¼Œä¸‹é¢çš„å‡½æ•°é‡Œé¢çš„ Variable åº”è¯¥æ”¹æˆ Tensor
# å› ä¸º Variable åœ¨ PyTorch ä¸­æ˜¯ç”¨äºæ±‚æ¢¯åº¦çš„æ•°æ®å¯¹è±¡ï¼Œè€Œåœ¨ MindSpore ä¸­ï¼Œåªæœ‰ Parameter æ‰éœ€è¦æ±‚æ¢¯åº¦ã€‚
Tensor


# PyTorch
torch.nn.functional.conv2d(inputs, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)

# MindSpore
pad_mode = 'pad'
conv = mindspore.nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel_size, stride=self.stride, pad_mode=pad_mode, padding=self.padding, dilation=self.dilation, group=self.groups)
conv.weight = self.weight
conv.bias = self.bias


# PyTorch
torch.nn.BatchNorm2d(
    num_features,
    eps=1e-05,
    momentum=0.1,
    affine=True,
    track_running_stats=True
)

# MindSporeï¼Œå‚æ•° track_running_stats å’Œ use_batch_statistics åŠŸèƒ½ä¸€è‡´ï¼Œä¸åŒå€¼å¯¹åº”çš„é»˜è®¤æ–¹å¼ä¸åŒ
# https://www.mindspore.cn/docs/zh-CN/r2.0/note/api_mapping/pytorch_diff/BatchNorm2d.html
# ä¸¤ä¸ªä¸»è¦åŒºåˆ«ï¼šhttps://www.mindspore.cn/docs/zh-CN/r2.0/migration_guide/typical_api_comparision.html#nn.BatchNorm2d
mindspore.nn.BatchNorm2d(
    num_features,
    eps=1e-5,
    momentum=0.9,
    affine=True,
    gamma_init='ones',
    beta_init='zeros',
    moving_mean_init='zeros',
    moving_var_init='ones',
    use_batch_statistics=None,
    data_format='NCHW'
)


# PyTorch
torch.nn.functional.batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)

# MindSpore
# https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/ops/mindspore.ops.batch_norm.html
mindspore.ops.batch_norm(input, moving_mean, moving_variance, weight, bias, training, momentum, eps)


# PyTorch
result = torch.nn.functional.instance_norm(input, None, None, weight, bias, training, momentum, eps)

# MindSpore
# https://www.mindspore.cn/docs/zh-CN/r2.0/note/api_mapping/pytorch_diff/InstanceNorm2d.html
# InstanceNorm ä»…æ”¯æŒåœ¨ GPU ä¸Šè¿è¡Œ
mindspore.nn.InstanceNorm2d(num_features, eps, momentum, affine=True, gamma_init, beta_init)


# PyTorch
weight_init = 1
self.weight.data.fill_(weight_init)

# MindSpore
self.gamma.set_data(mindspore.common.initializer.initializer("ones", self.gamma.shape, self.gamma.dtype))


# PyTorch
bias_init = 0
self.bias.data.fill_(bias_init)

# MindSpore
self.beta.set_data(mindspore.common.initializer.initializer("zeros", self.beta.shape, self.beta.dtype))


# PyTorch
self.weight.data.fill_(weight_init)
self.weight.requires_grad_(True)

# MindSpore
self.gamma = mindspore.Parameter(mindspore.common.initializer.initializer(gamma_init, self.gamma.shape, self.gamma.dtype), name="gamma", requires_grad=True)


# PyTorch
torch.nn.init.constant_(self.weight, 0.0)

# MindSpore
self.gamma.set_data(mindspore.common.initializer.initializer("zeros", self.gamma.shape, self.gamma.dtype))


# PyTorch
nn.Conv2d()

# MindSporeï¼Œåªæœ‰ pad_modeï¼Œhas_bias å‚æ•°ä¸ä¸€è‡´
# https://www.mindspore.cn/docs/zh-CN/r2.0/note/api_mapping/pytorch_diff/Conv2d.html
nn.Conv2d()


# PyTorch
conv = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)

# MindSpore
conv = nn.Conv2d(planes, planes, kernel_size=3, stride=1, pad_mode='pad', padding=1, has_bias=False)


# PyTorch
x_normalized = torch.nn.functional.normalize(x, p=2, dim=-1)

# MindSpore
l2_normalize = mindspore.ops.L2Normalize(axis=-1)
x_normalized = l2_normalize(x)
# æˆ–è€…
x_normalized = mindspore.ops.L2Normalize(axis=-1)(x)


# PyTorch
for module in m.modules():
# æˆ–è€…
for name, module in m.named_modules():

# MindSpore
for _, cell in m.cells_and_names():


# PyTorch
nn.init.normal_(m.weight, mean=0.0, std=1.0)

# MindSporeï¼Œåˆ°åº•æ˜¯ weight è¿˜æ˜¯ gammaï¼Œä¾æƒ…å†µè€Œå˜
m.weight.set_data(mindspore.common.initializer.initializer(mindspore.common.initializer.Normal(sigma=1.0, mean=0.0), m.weight.shape, m.weight.dtype))

# å®ä¾‹ï¼š
# PyTorch
for name, m in self.cells_and_names():
    if isinstance(m, MetaConv2d):
        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
		nn.init.normal_(m.weight, 0, math.sqrt(2. / n))
    elif isinstance(m, nn.BatchNorm2d):
		nn.init.constant_(m.weight, 1)
		nn.init.constant_(m.bias, 0)

# MindSpore
for name, m in self.cells_and_names():
    if isinstance(m, MetaConv2d):
        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
        m.weight.set_data(mindspore.common.initializer.initializer(mindspore.common.initializer.Normal(sigma=math.sqrt(2. / n), mean=0.0), m.weight.shape, m.weight.dtype))
    elif isinstance(m, nn.BatchNorm2d):
        m.gamma.set_data(mindspore.common.initializer.initializer("ones", m.gamma.shape, m.gamma.dtype))
        m.beta.set_data(mindspore.common.initializer.initializer("zeros", m.beta.shape, m.beta.dtype))
        

# PyTorch
Module._modules

# MindSpore
Cell._cells


# PyTorch
state_dict = torch.load(pretrain_path, map_location=torch.device('cpu'))

# MindSporeï¼Œä¸èƒ½ä½¿ç”¨ pytorch ä¿å­˜çš„ ckpt æ–‡ä»¶ï¼Œä¸èƒ½è¯»å– pth æ–‡ä»¶
state_dict = mindspore.load_checkpoint(pretrain_path)


# PyTorch
torch.optim.SGD

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_api_mapping.html
mindspore.nn.SGD


# PyTorch
torch.optim.Optimizer

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_api_mapping.html
mindspore.nn.Optimizer


# PyTorch
for module_param_name, value in module.named_parameters():
    model_dict[module_param_name] = value

# MindSpore
for item in model.get_parameters():
    model_dict[item.name] = item.value()


# PyTorch
names_weights_copy = dict()
for name, param in self.model.named_parameters():
    if param.requires_grad:
        names_weights_copy['self.model.' + name] = param

# MindSpore
names_weights_copy = dict()
for item in self.model.trainable_params():
    names_weights_copy['self.model.' + item.name] = item.value()


# PyTorch
torch.optim.lr_scheduler.CosineAnnealingLR

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_diff/CosineDecayLr.html
mindspore.nn.cosine_decay_lr


# PyTorch
torch.optim.lr_scheduler.WarmupLR

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/nn/mindspore.nn.WarmUpLR.html
mindspore.nn.WarmUpLR


# PyTorch
torch.utils.data.sampler.BatchSampler

# MindSpore



# PyTorch
torch.utils.data.DataLoader

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_diff/DataLoader.html
mindspore.dataset.GeneratorDataset


# PyTorch
torch.no_grad

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/migration_guide/typical_api_comparision.html
æ— 
# åœ¨ PyTorch ä¸­ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰§è¡Œæ­£å‘è®¡ç®—æ—¶ä¼šè®°å½•åå‘ä¼ æ’­æ‰€éœ€çš„ä¿¡æ¯ï¼Œåœ¨æ¨ç†é˜¶æ®µæˆ–æ— éœ€åå‘ä¼ æ’­ç½‘ç»œä¸­ï¼Œè¿™ä¸€æ“ä½œæ˜¯å†—ä½™çš„ï¼Œä¼šé¢å¤–è€—æ—¶ï¼Œå› æ­¤ï¼ŒPyTorch æä¾›äº†torch.no_grad æ¥å–æ¶ˆè¯¥è¿‡ç¨‹ã€‚
# è€Œ MindSpore åªæœ‰åœ¨è°ƒç”¨gradæ‰ä¼šæ ¹æ®æ­£å‘å›¾ç»“æ„æ¥æ„å»ºåå‘å›¾ï¼Œæ­£å‘æ‰§è¡Œæ—¶ä¸ä¼šè®°å½•ä»»ä½•ä¿¡æ¯ï¼Œæ‰€ä»¥ MindSpore å¹¶ä¸éœ€è¦è¯¥æ¥å£ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸º MindSpore çš„æ­£å‘è®¡ç®—å‡åœ¨torch.no_grad æƒ…å†µä¸‹è¿›è¡Œçš„ã€‚


# PyTorch
torch.nn.functional.adaptive_avg_pool2d

# MindSpore
mindspore.ops.adaptive_avg_pool2d


# PyTorch
torch.Tensor.expand(3, 3)

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_diff/expand.html
mindspore.Tensor.broadcast_to((3, 3))


# PyTorch type(distmat) = Tensor
# distmat = 1 * distmat - 2 * (inputs @ mat2)
distmat.addmm_(1, -2, inputs, mat2)

# MindSpore 
distmat = mindspore.ops.addmm(distmat, inputs, mat2, beta=1, alpha=-2)


# PyTorch
Tensor.clone()

# MindSpore
Tensor


# PyTorch
torch.Tensor.mul_(other)

# MindSpore
Tensor = mindspore.ops.mul(Tensor, other)


# PyTorch
torch.Tensor.resize_as_(Tensor)

# MindSpore
mindspore.Tensor.resize(*Tensor.shape)


# PyTorch
y = x.new().resize_as_(x).fill_(1)

# MindSpore
y = x.new_ones(x.shape)


# PyTorch
torch.Tensor.fill_(1)

# MindSpore
mindspore.ops.full(Tensor.shape, 1)


# PyTorch
torch.norm

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/ops/mindspore.ops.norm.html
mindspore.ops.norm


# PyTorch
torch.Tensor.sum(dim=None, keepdim=False, dtype=None)

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.2/note/api_mapping/pytorch_diff/TensorSum.html
torch.Tensor.sum((axis=None, dtype=None, keepdims=False, initial=None)
                 

# PyTorch
torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_diff/ones.html
mindspore.ops.ones(shape, dtype=dtype)


# PyTorch
nn.Module.add_module

# MindSpore
nn.Cell.insert_child_to_cell


# PyTorch
output, inverse_indices = torch.unique(x, return_inverse=True)

# MindSpore
output, idx = mindspore.ops.unique(x)


# PyTorch
output = torch.unique(x)

# MindSpore
output, idx = mindspore.ops.unique(x)


# PyTorch
torch.tensor.data

# MindSpore
mindspore.tensor.value()


# PyTorch
torch.nn.functional.linear(inputs, weight, bias)

# MindSpore
mindspore.ops.matmul(inputs, weight.T) + bias


# PyTorch
num_gpus = torch.cuda.device_count()

# MindSpore
def get_gpu_num():
    import argparse
    parser = argparse.ArgumentParser(description="å¤„ç†å‘½ä»¤è¡Œå‚æ•°")
    parser.add_argument('--num-gpus', type=int, default=1, help='GPUçš„æ•°é‡')
    parser.add_argument("--config-file", default="", metavar="FILE", help="path to config file")
	# è¿™é‡Œè¦è§£ææ‰€æœ‰å‚æ•°ï¼Œä¸ç„¶ä¼šæŠ¥é”™ï¼Œè¿™é‡Œåªè§£æä¸¤ä¸ª
    args = parser.parse_args()
    return args.num_gpus

num_gpus = get_gpu_num()


# PyTorch
grad_params = torch.autograd.grad(outputs=losses.mean(), inputs=names_weights_copy.values(), create_graph=True, allow_unused=True)

# MindSpore https://www.mindspore.cn/docs/zh-CN/r2.2/api_python/mindspore/mindspore.grad.html
grad_params = mindspore.grad(lambda x: x, grad_position=None, weights=model.trainable_params(), has_aux=False)(losses.mean())
# æˆ–è€…
def ff(x):
	return x
grad_params = mindspore.grad(ff, grad_position=None, weights=model.trainable_params(), has_aux=False)(losses.mean())


# PyTorch
grad_params[i] = Variable(grad_params[i].data, requires_grad=False)

# MindSpore
grad_params[i] = mindspore.Parameter(grad_params[i].value(), requires_grad=False)


# PyTorch
torch.save(model.state_dict(), save_pth_path)

# MindSpore
mindspore.save_checkpoint(model, save_ckpt_path)
```

## é™æ€å›¾è°ƒè¯•è®°å½•

MindSpore æ”¯æŒçš„ python è¯­æ³•ï¼šhttps://www.mindspore.cn/docs/zh-CN/r2.0/note/static_graph_syntax_support.html

```
Traceback (most recent call last):
  File "/home/yuming/ACL-DGReID-mindspore/test/unitest/test.py", line 100, in test_ResNet
    output_tensor = ms_model(input_tensor, epoch)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 620, in __call__
    out = self.compile_and_run(*args, **kwargs)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 939, in compile_and_run
    self.compile(*args, **kwargs)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 916, in compile
    _cell_graph_executor.compile(self, phase=self.phase,
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/common/api.py", line 1388, in compile
    result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode())
TypeError: 'self.NL_1_idx' should be initialized as a 'Parameter' type in the '__init__' function, but got '[]' with type 'list.

In file /home/yuming/ACL-DGReID-mindspore/fastreid/modeling/backbones/meta_dynamic_router_resnet.py:429
        if len(self.NL_1_idx) == 0:
               ^

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/ccsrc/pipeline/jit/parse/parse.cc:2708 HandleAssignClassMember
```

å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://www.mindspore.cn/docs/zh-CN/r2.0/note/static_graph_syntax_support.html#%E7%BD%91%E7%BB%9C%E4%BD%BF%E7%94%A8%E7%BA%A6%E6%9D%9F

ä¸å…è®¸ä¿®æ”¹ç½‘ç»œçš„é`Parameter`ç±»å‹æ•°æ®æˆå‘˜ã€‚ä¿®æ”¹ä¸º Parameter åˆå§‹åŒ–å°±è¡Œã€‚



```
Traceback (most recent call last):
  File "/home/yuming/ACL-DGReID-mindspore/test/unitest/test.py", line 101, in test_ResNet
    output_tensor = ms_model(input_tensor, epoch)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 620, in __call__
    out = self.compile_and_run(*args, **kwargs)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 939, in compile_and_run
    self.compile(*args, **kwargs)
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/nn/cell.py", line 916, in compile
    _cell_graph_executor.compile(self, phase=self.phase,
  File "/home/yuming/miniconda3/envs/reid/lib/python3.9/site-packages/mindspore/common/api.py", line 1388, in compile
    result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode())
AttributeError: 'Attribute' object has no attribute 'id'
```



```
TypeError: Only support assign to attribute of self, but got attribute of linear.
```

åŸæ¥çš„ä»£ç 

```python
class MetaLinear(nn.Dense):
    def __init__(self, in_channels, out_channels, has_bias=False):
        super().__init__(in_channels, out_channels, has_bias=has_bias)

    def construct(self, inputs, opt = None, reserve = False):
        linear = nn.Dense(self.in_channels, self.out_channels, has_bias=self.has_bias)
        if opt != None and opt['meta']:
            output = linear(inputs)
            return output
        else:
            output = linear(inputs)
            return output
```

ä¿®æ”¹å

```python
class MetaLinear(nn.Dense):
    def __init__(self, in_channels, out_channels, has_bias=False):
        super().__init__(in_channels, out_channels, has_bias=has_bias)
        self.linear = nn.Dense(self.in_channels, self.out_channels, has_bias=self.has_bias)

    def construct(self, inputs, opt = None, reserve = False):
        if opt != None and opt['meta']:
            output = self.linear(inputs)
            return output
        else:
            output = self.linear(inputs)
            return output
```



```
RuntimeError: Unsupported statement 'Delete'.
```

å‡ºé”™çš„ä»£ç 

```python
del opt['grad_params'][0]
```

ä¿®æ”¹å

```python
opt['grad_params'].pop(0)
```



```
NameError: The name 'c' is not defined, or not supported in graph mode.
```

å‡ºé”™çš„ä»£ç 

```python
def a(b):
	if b == 1:
		c = 2
    return c
```

ä¿®æ”¹å

```python
def a(b):
	c = None
	if b == 1:
		c = 2
    return c
```



æŠ¥é”™ï¼š

```
TypeError: The 4th initializing input to create instance for class 'mindspore.nn.layer.normalization.InstanceNorm2d' should be a constant, but got: AbstractKeywordArg(key: gamma_init, value: AbstractRefTensor(key: layer1.0.bn1.IN.gamma ref_value: AbstractRefTensor(shape: (32), element: AbstractScalar(Type: Float32, Value: ValueAny, Shape: NoShape), value_ptr: 0x5646bd968040, value: ValueAny), value: ValueAny))
```

gamma_init åˆå§‹åŒ–é”™è¯¯ï¼Œé™æ€å›¾æ„å›¾æ—¶å°±éœ€è¦è·å– init çš„å€¼ï¼Œä»£ç ä¸­çš„ gamma_init çŠ¶æ€éœ€è¦é€šè¿‡ construct è·å–ã€‚è¿™ç§æƒ…å†µä¸€èˆ¬éœ€è¦é‡å†™BNå±‚ï¼Œä¸èƒ½ç»§æ‰¿ã€‚



æŠ¥é”™ï¼š

```
RuntimeError: BUG: no manager for this func graph: fastreid_modeling_ops_MetaConv2d_construct.82
```

å‡ºé”™çš„ä»£ç ï¼š

```python
class MetaConv2d(nn.Conv2d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, group=1, bias=True, pad_mode='pad'):
        super().__init__(in_channels, out_channels, kernel_size, stride, pad_mode, padding, dilation, group, has_bias=bias)

        self.pad_mode = 'pad'

        self.w_step_size = 1
        self.b_step_size = 1
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, pad_mode=pad_mode, padding=padding, dilation=dilation, group=group)
        self.conv.weight = self.weight

    def construct(self, inputs, opt=None):
        if opt and opt['meta']:
            updated_weight = update_parameter(self.weight, self.w_step_size, opt)
            updated_bias = update_parameter(self.bias, self.b_step_size, opt)
            output = self.conv(inputs)
            return output
        else:
            output = self.conv(inputs)
            return output
```

construct å…¥å€¼ä¸èƒ½å«æœ‰ None å€¼ï¼Œä¿®æ”¹ä¸ºï¼š

```python
class MetaConv2d(nn.Conv2d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, group=1, bias=True, pad_mode='pad'):
        super().__init__(in_channels, out_channels, kernel_size, stride, pad_mode, padding, dilation, group, has_bias=bias)

        self.pad_mode = 'pad'

        self.w_step_size = 1
        self.b_step_size = 1
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, pad_mode=pad_mode, padding=padding, dilation=dilation, group=group)
        self.conv.weight = self.weight

    def construct(self, inputs, opt=0):
        if opt and opt['meta']:
            updated_weight = update_parameter(self.weight, self.w_step_size, opt)
            updated_bias = update_parameter(self.bias, self.b_step_size, opt)
            output = self.conv(inputs)
            return output
        else:
            output = self.conv(inputs)
            return output
```

## è®­ç»ƒä»£ç è°ƒè¯•

æŠ¥é”™ï¼š

```
sub_(): argument 'other' (position 1) must be Tensor, not StubTensor
```

è§£å†³ï¼š

ä¼ å…¥çš„æ˜¯ torch Tensorï¼Œå‰é¢äº§ç”Ÿå‘é‡çš„ pytorch ä»£ç æ²¡æœ‰è½¬å†™åˆ° mindsporeã€‚

åœ¨åŠ¨æ€å›¾ä¸‹ä¸ºäº†åŠ é€Ÿæ‰§è¡Œæ€§èƒ½ï¼Œä½¿ç®—å­çš„æ‰§è¡Œè¿‡ç¨‹èƒ½å¤Ÿè¿›è¡Œå¼‚æ­¥æ‰§è¡Œï¼Œæ­¤å¤„è¿”å›çš„æ˜¯ä¸€ä¸ªæ‰“æ¡©å¼ é‡ï¼ˆStubTensorï¼Œå³è¿™ä¸ªtensorä¸æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„Tensorï¼Œä½†å…·æœ‰Tensorçš„æ‰€æœ‰æ–¹æ³•å’Œå±æ€§ï¼‰ï¼›å½“ç”¨æˆ·è„šæœ¬ä¸­å»çœŸæ­£ä½¿ç”¨è¿™ä¸ªå¼ é‡æ—¶ï¼Œæˆ‘ä»¬æ‰ä¼šå°†å…·ä½“çš„æ•°æ®åŒæ­¥å›æ¥ã€‚

## Reference

[å®˜ç½‘ç½‘ç»œè¿ç§»è°ƒè¯•å®ä¾‹](https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/migration_guide/sample_code.html)

[å®˜æ–¹æ–‡æ¡£ä¸­ MindSpore ä¸ PyTorch å…¸å‹åŒºåˆ«](https://www.mindspore.cn/docs/zh-CN/r2.0/migration_guide/typical_api_comparision.html)

[PyTorch ä¸ MindSpore API æ˜ å°„è¡¨](https://www.mindspore.cn/docs/zh-CN/r2.0/note/api_mapping/pytorch_api_mapping.html)

å®˜æ–¹è¿ç§»å®ä¾‹ï¼š

https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/source_zh_cn/migration_guide/code/resnet_convert/resnet_ms/src/resnet.py

https://gitee.com/mindspore/mindscience/tree/master/MindSPONGE/applications/research/DeepFRI

https://gitee.com/mindspore/mindscience/tree/master/MindSPONGE/applications/MEGAProtein

å®˜ç½‘å…³äº MindSpore çš„ç‰¹æ€§è§£ç­”ï¼šhttps://www.mindspore.cn/docs/zh-CN/r2.0/faq/feature_advice.html?highlight=pth